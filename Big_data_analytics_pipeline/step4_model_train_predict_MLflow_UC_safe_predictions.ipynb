{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b9b68da-4354-44c1-9b09-dec16aa26141",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Step 4 complete (no-ML scorer). Predictions saved to: influencer.ml.creator_predictions\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>creator_norm_id</th><th>success_prob</th><th>label</th></tr></thead><tbody><tr><td>8bc07220b1f7b0dceef13078018877a7da5e450703262d5dfcfd25040e2d1dfc</td><td>0.04742587317756678</td><td>0</td></tr><tr><td>742419aa8e7450263ad85b8b534b3d5ffa16055748a7cc933522ff962a8d76cc</td><td>0.04742587317756678</td><td>0</td></tr><tr><td>00b7c47c8ff06f8570d69042134a8b86650c18433078c5b419182eae9e918bb2</td><td>0.04742587317756678</td><td>0</td></tr><tr><td>e46e5ad757ac6efc118a88e74c7bd625eaabf6b4189ec1f27ec31a368bb72bf3</td><td>0.04742587317756678</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "8bc07220b1f7b0dceef13078018877a7da5e450703262d5dfcfd25040e2d1dfc",
         0.04742587317756678,
         0
        ],
        [
         "742419aa8e7450263ad85b8b534b3d5ffa16055748a7cc933522ff962a8d76cc",
         0.04742587317756678,
         0
        ],
        [
         "00b7c47c8ff06f8570d69042134a8b86650c18433078c5b419182eae9e918bb2",
         0.04742587317756678,
         0
        ],
        [
         "e46e5ad757ac6efc118a88e74c7bd625eaabf6b4189ec1f27ec31a368bb72bf3",
         0.04742587317756678,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "creator_norm_id",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "success_prob",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "label",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MAGIC %run ./00_config\n",
    "# STEP 4: Success probability via normalized features + weighted sigmoid (no ML objects, no clip)\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# ---- Safe fallback if 00_config didn’t run ----\n",
    "try:\n",
    "    tbl  # type: ignore\n",
    "except NameError:\n",
    "    CATALOG = \"influencer\"\n",
    "    def tbl(name: str) -> str:\n",
    "        return f\"{CATALOG}.{name}\"\n",
    "\n",
    "features_tbl = tbl(\"ml.creator_features\")\n",
    "if not spark.catalog.tableExists(features_tbl):\n",
    "    raise RuntimeError(f\"❌ Feature table not found: {features_tbl} — run Step 3 first!\")\n",
    "\n",
    "df = spark.table(features_tbl).fillna(0)\n",
    "\n",
    "# ---- Choose feature set ----\n",
    "feat_cols = [\n",
    "    \"avg_eng_rate\", \"avg_like\", \"avg_comment\", \"avg_share\",\n",
    "    \"avg_female_ratio\", \"activity_score\", \"avg_age_25_34\", \"avg_align\"\n",
    "]\n",
    "feat_cols = [c for c in feat_cols if c in df.columns]\n",
    "if not feat_cols:\n",
    "    raise RuntimeError(\"❌ No expected feature columns found. Check Step 3 output schema.\")\n",
    "\n",
    "# ---- Quantile-based normalization (no clip) ----\n",
    "eps = 1e-9\n",
    "for c in feat_cols:\n",
    "    q = df.approxQuantile(c, [0.05, 0.95], 1e-3)\n",
    "    lo = float(q[0]) if len(q) > 0 else 0.0\n",
    "    hi = float(q[1]) if len(q) > 1 else lo + 1.0\n",
    "    if hi - lo <= 0:\n",
    "        hi = lo + 1.0\n",
    "    df = df.withColumn(f\"nz_{c}\", F.when(F.col(c).isNull(), 0.0).otherwise(F.col(c)))\n",
    "    norm_expr = (F.col(f\"nz_{c}\") - F.lit(lo)) / F.lit((hi - lo) + eps)\n",
    "    # Clamp between 0 and 1 manually\n",
    "    norm_expr = F.when(norm_expr < 0, 0).when(norm_expr > 1, 1).otherwise(norm_expr)\n",
    "    df = df.withColumn(f\"norm_{c}\", norm_expr)\n",
    "\n",
    "# ---- Feature weights ----\n",
    "w = {\n",
    "    \"avg_eng_rate\": 0.30, \"avg_like\": 0.10, \"avg_comment\": 0.10, \"avg_share\": 0.10,\n",
    "    \"avg_female_ratio\": 0.05, \"activity_score\": 0.15, \"avg_age_25_34\": 0.10, \"avg_align\": 0.10\n",
    "}\n",
    "w = {f: w[f] for f in feat_cols if f in w}\n",
    "wsum = sum(w.values()) or 1.0\n",
    "w = {k: v / wsum for k, v in w.items()}\n",
    "\n",
    "# ---- Weighted score ----\n",
    "raw = None\n",
    "for c in w:\n",
    "    term = F.col(f\"norm_{c}\") * F.lit(w[c])\n",
    "    raw = term if raw is None else (raw + term)\n",
    "df = df.withColumn(\"raw_score\", raw)\n",
    "\n",
    "# ---- Map to probability via sigmoid ----\n",
    "a, b = 6.0, 0.5\n",
    "df = df.withColumn(\"success_prob\", 1 / (1 + F.exp(-a * (F.col(\"raw_score\") - F.lit(b)))))\n",
    "\n",
    "# ---- Heuristic label for validation ----\n",
    "thr = float(df.approxQuantile(\"raw_score\", [0.6], 1e-3)[0])\n",
    "df = df.withColumn(\"label\", (F.col(\"raw_score\") > F.lit(thr)).cast(\"int\"))\n",
    "\n",
    "# ---- Save predictions ----\n",
    "pred_tbl = tbl(\"ml.creator_predictions\")\n",
    "(df.select(\"creator_norm_id\", \"success_prob\", \"label\")\n",
    "   .write.format(\"delta\")\n",
    "   .mode(\"overwrite\")\n",
    "   .option(\"overwriteSchema\", \"true\")\n",
    "   .saveAsTable(pred_tbl))\n",
    "\n",
    "print(f\"✅ Step 4 complete (no-ML scorer). Predictions saved to: {pred_tbl}\")\n",
    "display(spark.table(pred_tbl).orderBy(F.desc(\"success_prob\")).limit(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f73062e-d389-40ac-8746-9c4cdcb70a8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "step4_model_train_predict_MLflow_UC_safe_predictions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}